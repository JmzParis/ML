{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Capacity for Separating 2D Spot Clouds\n",
    "\n",
    "This notebook demonstrates how a simple feed-forward neural network, built with PyTorch, can learn to classify points belonging to different clusters (spot clouds) in a 2D plane. We will visualize the data and the learned decision boundaries using Matplotlib.\n",
    "\n",
    "We'll start with a simple case of 2 well-separated clouds and gradually increase the complexity by adding more clouds. We may need to adjust the network architecture (layers/neurons) as the task becomes harder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup: Import Libraries and Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to plot data and decision boundaries\n",
    "def plot_decision_boundary(model, X, y, title=\"Decision Boundary\"):\n",
    "    \"\"\"\n",
    "    Plots the data points and the decision boundary learned by the model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The trained PyTorch model.\n",
    "        X (torch.Tensor): Feature data (input).\n",
    "        y (torch.Tensor): Target labels.\n",
    "        title (str): Title for the plot.\n",
    "    \"\"\"\n",
    "    model.eval() # Set model to evaluation mode\n",
    "\n",
    "    # Convert tensors to numpy for plotting if they are on GPU\n",
    "    X_np = X.cpu().numpy()\n",
    "    y_np = y.cpu().numpy()\n",
    "\n",
    "    # Define the grid range based on data\n",
    "    x_min, x_max = X_np[:, 0].min() - 1, X_np[:, 0].max() + 1\n",
    "    y_min, y_max = X_np[:, 1].min() - 1, X_np[:, 1].max() + 1\n",
    "    h = 0.02 # step size in the mesh\n",
    "\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    # Predict class for each point in the mesh grid\n",
    "    grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "    grid_points_tensor = torch.tensor(grid_points, dtype=torch.float32).to(device)\n",
    "\n",
    "    with torch.no_grad(): # No need to track gradients for inference\n",
    "        Z = model(grid_points_tensor)\n",
    "        _, predicted = torch.max(Z.data, 1)\n",
    "        predicted_np = predicted.cpu().numpy()\n",
    "\n",
    "    # Reshape predictions to match the grid shape\n",
    "    Z = predicted_np.reshape(xx.shape)\n",
    "\n",
    "    # Plot the contour and training examples\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n",
    "    scatter = plt.scatter(X_np[:, 0], X_np[:, 1], c=y_np, cmap=plt.cm.Spectral, edgecolors='k')\n",
    "\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.title(title)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "    # Add legend if number of classes is reasonable\n",
    "    num_classes = len(np.unique(y_np))\n",
    "    if num_classes <= 10:\n",
    "       handles, labels = scatter.legend_elements()\n",
    "       legend_labels = [f'Cloud {i}' for i in range(num_classes)]\n",
    "       plt.legend(handles, legend_labels, title=\"Classes\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple Neural Network Model\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        # No final activation, CrossEntropyLoss will handle it\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "def train_model(model, X_train, y_train, learning_rate=0.01, num_epochs=1000, print_loss_every=100):\n",
    "    \"\"\"Trains the provided model.\"\"\"\n",
    "    model.train() # Set model to training mode\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    print(f\"\\n--- Training Started ---\")\n",
    "    # Get model details dynamically\n",
    "    if isinstance(model, SimpleNet):\n",
    "        print(f\"Model: SimpleNet\")\n",
    "        print(f\"Input Size: {model.fc1.in_features}, Hidden Size: {model.fc1.out_features}, Output Size: {model.fc2.out_features}\")\n",
    "    elif isinstance(model, DeeperNet): # Add this check if DeeperNet is defined later\n",
    "        print(f\"Model: DeeperNet\")\n",
    "        print(f\"Input Size: {model.fc1.in_features}, Hidden1: {model.fc1.out_features}, Hidden2: {model.fc2.out_features}, Output Size: {model.fc3.out_features}\")\n",
    "    else:\n",
    "        print(f\"Model: {model.__class__.__name__} (structure not explicitly printed)\")\n",
    "    print(f\"Epochs: {num_epochs}, Learning Rate: {learning_rate}\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % print_loss_every == 0 or epoch == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    print(\"--- Training Finished ---\")\n",
    "    # Calculate final accuracy on training data (simple metric for demo)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        outputs = model(X_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total = y_train.size(0)\n",
    "        correct = (predicted == y_train).sum().item()\n",
    "        print(f'Training Accuracy: {(100 * correct / total):.2f} %')\n",
    "    return model # Return trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scenario 1: Two Well-Separated Clouds\n",
    "\n",
    "We start with the simplest case: two distinct elliptical clouds generated using `make_blobs`. A simple network with one hidden layer should easily learn to separate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Scenario 1: Data Generation ---\n",
    "N_SAMPLES = 300\n",
    "N_FEATURES = 2\n",
    "N_CLASSES_1 = 2\n",
    "CENTERS_1 = [(-3, -3), (3, 3)] # Well-separated centers\n",
    "CLUSTER_STD_1 = 1.0 # Standard deviation of the clusters (controls spread)\n",
    "\n",
    "X1, y1 = make_blobs(n_samples=N_SAMPLES,\n",
    "                    n_features=N_FEATURES,\n",
    "                    centers=CENTERS_1,\n",
    "                    cluster_std=CLUSTER_STD_1,\n",
    "                    random_state=42) # Use random_state for reproducibility\n",
    "\n",
    "# Convert to PyTorch tensors and move to device\n",
    "X1_tensor = torch.tensor(X1, dtype=torch.float32).to(device)\n",
    "y1_tensor = torch.tensor(y1, dtype=torch.long).to(device) # CrossEntropyLoss expects Long type\n",
    "\n",
    "print(f\"Generated {X1.shape[0]} samples for {N_CLASSES_1} classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the raw data for Scenario 1\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X1[:, 0], X1[:, 1], c=y1, cmap=plt.cm.Spectral, edgecolors='k')\n",
    "plt.title('Scenario 1: Raw Data (2 Clouds)')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define and train a simple neural network for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Scenario 1: Model Definition, Training, and Visualization ---\n",
    "\n",
    "# Model Parameters\n",
    "INPUT_SIZE = N_FEATURES\n",
    "HIDDEN_SIZE_1 = 8 # A small number of neurons should suffice\n",
    "OUTPUT_SIZE_1 = N_CLASSES_1\n",
    "\n",
    "# Instantiate the model and move to device\n",
    "model1 = SimpleNet(INPUT_SIZE, HIDDEN_SIZE_1, OUTPUT_SIZE_1).to(device)\n",
    "\n",
    "# Train the model\n",
    "model1 = train_model(model1, X1_tensor, y1_tensor, num_epochs=500, learning_rate=0.02)\n",
    "\n",
    "# Plot decision boundary\n",
    "plot_decision_boundary(model1, X1_tensor, y1_tensor, title=f\"Scenario 1: Decision Boundary (Hidden Size={HIDDEN_SIZE_1})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the simple neural network with 8 hidden neurons easily finds a linear boundary (due to the ReLU activation and subsequent linear layer) to separate the two well-defined clouds. The training accuracy should be high (likely 100%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scenario 2: Three Clouds\n",
    "\n",
    "Now, let's add a third cloud. The task becomes slightly more complex, requiring the network to learn non-linear boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Scenario 2: Data Generation ---\n",
    "N_CLASSES_2 = 3\n",
    "CENTERS_2 = [(-4, 0), (4, 0), (0, 5)] # Three distinct centers\n",
    "CLUSTER_STD_2 = 1.2\n",
    "\n",
    "X2, y2 = make_blobs(n_samples=N_SAMPLES,\n",
    "                    n_features=N_FEATURES,\n",
    "                    centers=CENTERS_2,\n",
    "                    cluster_std=CLUSTER_STD_2,\n",
    "                    random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors and move to device\n",
    "X2_tensor = torch.tensor(X2, dtype=torch.float32).to(device)\n",
    "y2_tensor = torch.tensor(y2, dtype=torch.long).to(device)\n",
    "\n",
    "print(f\"Generated {X2.shape[0]} samples for {N_CLASSES_2} classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the raw data for Scenario 2\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X2[:, 0], X2[:, 1], c=y2, cmap=plt.cm.Spectral, edgecolors='k')\n",
    "plt.title('Scenario 2: Raw Data (3 Clouds)')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a model for this 3-class problem. We might use slightly more neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Scenario 2: Model Definition, Training, and Visualization ---\n",
    "\n",
    "# Model Parameters\n",
    "OUTPUT_SIZE_2 = N_CLASSES_2\n",
    "# We might keep the hidden size the same or slightly increase it if needed\n",
    "HIDDEN_SIZE_2 = 10 # Let's try slightly more neurons\n",
    "\n",
    "# Instantiate the model and move to device\n",
    "model2 = SimpleNet(INPUT_SIZE, HIDDEN_SIZE_2, OUTPUT_SIZE_2).to(device)\n",
    "\n",
    "# Train the model\n",
    "model2 = train_model(model2, X2_tensor, y2_tensor, num_epochs=1000, learning_rate=0.01)\n",
    "\n",
    "# Plot decision boundary\n",
    "plot_decision_boundary(model2, X2_tensor, y2_tensor, title=f\"Scenario 2: Decision Boundary (Hidden Size={HIDDEN_SIZE_2})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network with 10 hidden neurons successfully learns the boundaries for the three clouds. The boundaries are formed by combinations of the linear separators learned by the hidden neurons, resulting in non-linear regions overall. Accuracy should still be quite high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scenario 3: Four Clouds (Potentially Closer)\n",
    "\n",
    "Let's increase the complexity further with four clouds. We can make them slightly closer or increase their standard deviation to make the separation task more challenging. This might require a network with more capacity (more neurons or layers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Scenario 3: Data Generation ---\n",
    "N_CLASSES_3 = 4\n",
    "CENTERS_3 = [(-3, -3), (3, 3), (-3, 3), (3, -3)] # Four corners\n",
    "CLUSTER_STD_3 = 1.3 # Slightly larger spread, potential for overlap\n",
    "\n",
    "X3, y3 = make_blobs(n_samples=N_SAMPLES,\n",
    "                    n_features=N_FEATURES,\n",
    "                    centers=CENTERS_3,\n",
    "                    cluster_std=CLUSTER_STD_3,\n",
    "                    random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors and move to device\n",
    "X3_tensor = torch.tensor(X3, dtype=torch.float32).to(device)\n",
    "y3_tensor = torch.tensor(y3, dtype=torch.long).to(device)\n",
    "\n",
    "print(f\"Generated {X3.shape[0]} samples for {N_CLASSES_3} classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the raw data for Scenario 3\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X3[:, 0], X3[:, 1], c=y3, cmap=plt.cm.Spectral, edgecolors='k')\n",
    "plt.title('Scenario 3: Raw Data (4 Clouds)')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Attempt with the Previous Architecture\n",
    "\n",
    "Let's first see how the previous architecture (10 hidden neurons) handles this slightly more complex scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Scenario 3a: Training with Previous Architecture ---\n",
    "\n",
    "# Model Parameters\n",
    "OUTPUT_SIZE_3 = N_CLASSES_3\n",
    "HIDDEN_SIZE_3a = 10 # Same as before\n",
    "\n",
    "# Instantiate the model and move to device\n",
    "model3a = SimpleNet(INPUT_SIZE, HIDDEN_SIZE_3a, OUTPUT_SIZE_3).to(device)\n",
    "\n",
    "# Train the model\n",
    "# May need more epochs or adjusted learning rate if convergence is slow/unstable\n",
    "model3a = train_model(model3a, X3_tensor, y3_tensor, num_epochs=2000, learning_rate=0.01)\n",
    "\n",
    "# Plot decision boundary\n",
    "plot_decision_boundary(model3a, X3_tensor, y3_tensor, title=f\"Scenario 3a: Decision Boundary (Hidden Size={HIDDEN_SIZE_3a})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the exact overlap and the initialization, the model with 10 hidden neurons might struggle to perfectly separate all four clouds, especially near the center. We might see some misclassified points or slightly irregular boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Attempt with Increased Capacity (More Neurons)\n",
    "\n",
    "Let's try increasing the capacity of the network by adding more neurons to the hidden layer. This allows the network to potentially learn more complex boundary shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Scenario 3b: Increasing Hidden Neurons ---\n",
    "\n",
    "# Model Parameters\n",
    "HIDDEN_SIZE_3b = 20 # Increase hidden neurons\n",
    "\n",
    "# Instantiate the model and move to device\n",
    "model3b = SimpleNet(INPUT_SIZE, HIDDEN_SIZE_3b, OUTPUT_SIZE_3).to(device)\n",
    "\n",
    "# Train the model\n",
    "model3b = train_model(model3b, X3_tensor, y3_tensor, num_epochs=2000, learning_rate=0.01)\n",
    "\n",
    "# Plot decision boundary\n",
    "plot_decision_boundary(model3b, X3_tensor, y3_tensor, title=f\"Scenario 3b: Decision Boundary (Hidden Size={HIDDEN_SIZE_3b})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With more hidden neurons (e.g., 20), the network usually achieves better separation for the four-cloud scenario. The boundaries might look smoother or more appropriate for the data distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 (Optional) Attempt with a Deeper Network\n",
    "\n",
    "If the separation is still challenging or for demonstration purposes, we could try adding another hidden layer. Deeper networks can sometimes capture hierarchical features, although for this relatively simple blob data, increasing width (neurons) is often sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Scenario 3c: Adding a Hidden Layer ---\n",
    "\n",
    "# Define a Deeper Network\n",
    "class DeeperNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, num_classes):\n",
    "        super(DeeperNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "# Model Parameters\n",
    "HIDDEN_SIZE1_3c = 16\n",
    "HIDDEN_SIZE2_3c = 8\n",
    "\n",
    "# Instantiate the model and move to device\n",
    "model3c = DeeperNet(INPUT_SIZE, HIDDEN_SIZE1_3c, HIDDEN_SIZE2_3c, OUTPUT_SIZE_3).to(device)\n",
    "\n",
    "# Train the model (might need more epochs for deeper nets)\n",
    "model3c = train_model(model3c, X3_tensor, y3_tensor, num_epochs=2500, learning_rate=0.01)\n",
    "\n",
    "# Plot decision boundary\n",
    "plot_decision_boundary(model3c, X3_tensor, y3_tensor, title=f\"Scenario 3c: Decision Boundary (Layers: {HIDDEN_SIZE1_3c}-{HIDDEN_SIZE2_3c})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A deeper network can also learn the separation. Comparing the results visually (and via accuracy) from Scenarios 3a, 3b, and 3c helps illustrate the trade-offs between network width and depth for a given task complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "This notebook demonstrated the ability of classical feed-forward neural networks to learn separation boundaries for clustered data in 2D.\n",
    "\n",
    "- For **well-separated clusters** (Scenario 1), a very simple network suffices.\n",
    "- As the **number of clusters increases** (Scenario 2), the network needs to learn more complex, non-linear boundaries, but a single hidden layer network often still performs well if the clusters remain reasonably distinct.\n",
    "- When the **task becomes more complex** (Scenario 3, with more clusters or closer proximity/overlap), we might need to increase the network's capacity:\n",
    "    - **Increasing Neurons (Width):** Adding more neurons in a hidden layer allows the network to learn more complex combinations of features (more intricate boundaries). This was shown effectively in Scenario 3b.\n",
    "    - **Adding Layers (Depth):** Adding more hidden layers allows the network to learn hierarchical features, potentially modeling more complex relationships in the data, as demonstrated optionally in Scenario 3c.\n",
    "\n",
    "The choice of architecture (number of layers and neurons) depends on the complexity of the data distribution. Overly complex models for simple data can lead to overfitting (though not very apparent here as we train on the whole dataset), while models that are too simple may underfit complex data (as potentially seen in Scenario 3a). Finding the right balance often involves experimentation and validation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
